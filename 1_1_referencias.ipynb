{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461a0134",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203afb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chains.consolidar_referencias import run_consolidacion_referencias\n",
    "from src.utils.loaders.load_results import get_brand_summary\n",
    "\n",
    "base_path = \"../data/results/models_extraction\"\n",
    "brand = \"AKT\"\n",
    "\n",
    "payload = get_brand_summary(brand, base_path)\n",
    "resultado = run_consolidacion_referencias(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34879e",
   "metadata": {},
   "source": [
    "## Obtener referencias de todas las marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from src.chains.consolidar_referencias import run_consolidacion_referencias\n",
    "from src.utils.loaders.load_results import get_brand_summary\n",
    "\n",
    "# --- Config ---\n",
    "base_path = \"../data/results/models_extraction\"\n",
    "OUTPUT_DIR = Path(\"../data/results/consolidacion_referencias\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lista de marcas a procesar\n",
    "brands = [\"AKT\", \"BAJAJ\", \"BENELLI\", \"HERO\", \"HONDA\", \"KAWASAKI\", \"KTM\", \"KYMCO\", \"ROYAL ENFIELD\",\n",
    "          \"SUZUKI\", \"TVS\", \"VICTORY\", \"YAMAHA\"]\n",
    "\n",
    "# --- Iterar sobre cada marca ---\n",
    "for brand in brands:\n",
    "    print(f\"Procesando {brand}...\")\n",
    "    payload = get_brand_summary(brand, base_path)\n",
    "    resultado = run_consolidacion_referencias(payload)\n",
    "\n",
    "    # Generar nombre de archivo con marca y timestamp\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    fname = f\"{brand.upper()}_{ts}.json\"\n",
    "    fpath = OUTPUT_DIR / fname\n",
    "\n",
    "    # Guardar el resultado en JSON\n",
    "    with open(fpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(resultado.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ Resultado para {brand} guardado en: {fpath.resolve()}\")\n",
    "\n",
    "print(\"Procesamiento completado para todas las marcas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ed400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919a3921",
   "metadata": {},
   "source": [
    "## Mapear referencia con titulo de repuesto y regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2869eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "RESULTS_DIR = \"../data/results/curated/consolidacion_referencias\"\n",
    "TITLE_COL = \"titulo_producto\"          # <-- ajusta si tu columna se llama distinto\n",
    "BRAND_COL = \"marca\"           # <-- ajusta si tu columna se llama distinto\n",
    "MARCAS_LLANTAS = {\"MICHELIN\", \"PIRELLI\", \"KONTROL\", \"METZELER\"}\n",
    "VALOR_NO_APLICA = \"NO APLICA\"\n",
    "DATA_PATH = \"../data/curated/shopify_data_cat_gen.pkl\"\n",
    "\n",
    "# -----------------------\n",
    "# Helpers carga/regex\n",
    "# -----------------------\n",
    "def load_json(path: str | Path) -> Dict[str, Any]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def canon_upper(s: str) -> str:\n",
    "    s2 = s.upper()\n",
    "    s2 = re.sub(r\"[\\s\\-_\\.]+\", \" \", s2)\n",
    "    s2 = re.sub(r\"\\s+\", \" \", s2).strip()\n",
    "    return s2\n",
    "\n",
    "_SEP = r\"[\\s\\-_\\.]*\"\n",
    "\n",
    "def _split_letters_digits(token: str) -> List[str]:\n",
    "    pieces = re.findall(r\"[A-Z]+|\\d+\", token)\n",
    "    return pieces if pieces else [token]\n",
    "\n",
    "def _variant_to_pattern(variant: str) -> str:\n",
    "    v = canon_upper(variant)\n",
    "    tokens: List[str] = []\n",
    "    for coarse in v.split():\n",
    "        tokens += _split_letters_digits(coarse)\n",
    "    parts = [re.escape(t) for t in tokens if t]\n",
    "    core = _SEP.join(parts) if parts else re.escape(v)\n",
    "    return rf\"(?<![A-Z0-9]){core}(?![A-Z0-9])\"\n",
    "\n",
    "# -----------------------\n",
    "# Índices por marca y global\n",
    "# -----------------------\n",
    "def build_index_from_consolidated(consolidated: Dict[str, Any], marca: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Devuelve entradas [{brand, referencia_base, variante, regex, weight}] ordenadas por especificidad.\"\"\"\n",
    "    entries: List[Dict[str, Any]] = []\n",
    "    for g in consolidated.get(\"grupos\", []):\n",
    "        ref_base = canon_upper(g[\"referencia\"])\n",
    "        variantes = g.get(\"variantes\", []) or [ref_base]\n",
    "        # asegúrate de incluir la referencia base como variante\n",
    "        if ref_base not in (canon_upper(x) for x in variantes):\n",
    "            variantes = [ref_base] + variantes\n",
    "        for v in variantes:\n",
    "            pat = _variant_to_pattern(v)\n",
    "            rx = re.compile(pat)\n",
    "            weight = (len(canon_upper(v)), len(re.findall(r\"[A-Z]+|\\d+\", canon_upper(v))))\n",
    "            entries.append({\n",
    "                \"brand\": canon_upper(marca),\n",
    "                \"referencia_base\": ref_base,\n",
    "                \"variante\": v,\n",
    "                \"regex\": rx,\n",
    "                \"weight\": weight,\n",
    "            })\n",
    "    entries.sort(key=lambda e: e[\"weight\"], reverse=True)\n",
    "    return entries\n",
    "\n",
    "def build_all_brand_indexes(results_dir: str | Path) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"Lee todos los JSON y construye un índice por marca.\"\"\"\n",
    "    idx_by_brand: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for fp in glob(f\"{results_dir}/*.json\"):\n",
    "        data = load_json(fp)\n",
    "        brand = canon_upper(data.get(\"marca\") or Path(fp).stem.split(\"_\")[0])\n",
    "        idx_by_brand[brand] = build_index_from_consolidated(data, brand)\n",
    "    return idx_by_brand\n",
    "\n",
    "def build_global_index(idx_by_brand: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Concatena todos los índices en uno global (ya vienen ordenados por peso).\"\"\"\n",
    "    all_entries: List[Dict[str, Any]] = []\n",
    "    for brand, entries in idx_by_brand.items():\n",
    "        all_entries.extend(entries)\n",
    "    # ordenar otra vez por si acaso\n",
    "    all_entries.sort(key=lambda e: e[\"weight\"], reverse=True)\n",
    "    return all_entries\n",
    "\n",
    "# -----------------------\n",
    "# Matching (TODAS las coincidencias)\n",
    "# -----------------------\n",
    "def find_all_matches(title: str, entries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Devuelve una lista de matches (sin duplicar por referencia):\n",
    "    [{brand, referencia_base, variante, span, text}]\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str) or not title:\n",
    "        return []\n",
    "    t = canon_upper(title)\n",
    "    seen_refs = set()\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for ent in entries:\n",
    "        m = ent[\"regex\"].search(t)\n",
    "        if m:\n",
    "            ref = ent[\"referencia_base\"]\n",
    "            if ref in seen_refs:\n",
    "                continue  # no repetir misma referencia base\n",
    "            seen_refs.add(ref)\n",
    "            span = m.span()\n",
    "            out.append({\n",
    "                \"brand\": ent[\"brand\"],\n",
    "                \"referencia_base\": ref,\n",
    "                \"variante\": ent[\"variante\"],\n",
    "                \"span\": span,\n",
    "                \"text\": t[span[0]:span[1]],\n",
    "            })\n",
    "    return out\n",
    "\n",
    "# -----------------------\n",
    "# Pipeline de consolidación\n",
    "# -----------------------\n",
    "def consolidar_modelos(\n",
    "    df: pd.DataFrame,\n",
    "    title_col: str = TITLE_COL,\n",
    "    brand_col: str = BRAND_COL,\n",
    "    results_dir: str | Path = RESULTS_DIR,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve un DF con columnas:\n",
    "      - ref_matches: lista de referencias que hicieron match (por fila)\n",
    "      - modelo: join con '|'\n",
    "      - (para GENERICO) marca_matches: lista de marcas detectadas por los matches\n",
    "      - (para GENERICO) marca_modelo: join con '|'\n",
    "      - para marcas de llantas: modelo = \"NO APLICA\"\n",
    "    \"\"\"\n",
    "    assert title_col in df.columns, f\"No existe columna {title_col}\"\n",
    "    assert brand_col in df.columns, f\"No existe columna {brand_col}\"\n",
    "\n",
    "    # construir índices\n",
    "    idx_by_brand = build_all_brand_indexes(results_dir)\n",
    "    global_idx = build_global_index(idx_by_brand)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[brand_col] = df[brand_col].astype(str).str.upper()\n",
    "\n",
    "    ref_matches_col = []\n",
    "    marca_matches_col = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        brand = row[brand_col]\n",
    "        title = row[title_col]\n",
    "\n",
    "        # 1) marcas de llantas -> NO APLICA\n",
    "        if brand in MARCAS_LLANTAS:\n",
    "            ref_matches_col.append([])   # sin matches\n",
    "            marca_matches_col.append([])\n",
    "            continue\n",
    "\n",
    "        # 2) GENERICO -> buscar en índice global (todas las marcas)\n",
    "        if brand == \"GENERICO\":\n",
    "            matches = find_all_matches(title, global_idx)\n",
    "            ref_matches = [m[\"referencia_base\"] for m in matches]\n",
    "            marca_matches = [m[\"brand\"] for m in matches]\n",
    "            # únicos preservando orden\n",
    "            def _uniq(seq): \n",
    "                seen=set(); out=[]\n",
    "                for x in seq:\n",
    "                    if x not in seen:\n",
    "                        seen.add(x); out.append(x)\n",
    "                return out\n",
    "            ref_matches_col.append(_uniq(ref_matches))\n",
    "            marca_matches_col.append(_uniq(marca_matches))\n",
    "            continue\n",
    "\n",
    "        # 3) resto de marcas -> buscar solo en su índice\n",
    "        entries = idx_by_brand.get(brand, [])\n",
    "        matches = find_all_matches(title, entries)\n",
    "        ref_matches = [m[\"referencia_base\"] for m in matches]\n",
    "        # únicos preservando orden\n",
    "        seen=set(); uniq=[]\n",
    "        for x in ref_matches:\n",
    "            if x not in seen:\n",
    "                seen.add(x); uniq.append(x)\n",
    "        ref_matches_col.append(uniq)\n",
    "        marca_matches_col.append([])\n",
    "\n",
    "    df[\"ref_matches\"] = ref_matches_col\n",
    "    df[\"marca_matches\"] = marca_matches_col  # útil solo para GENERICO\n",
    "\n",
    "    # modelo: join de todos los matches (o NO APLICA para llantas)\n",
    "    def _modelo_row(row):\n",
    "        if row[brand_col] in MARCAS_LLANTAS:\n",
    "            return VALOR_NO_APLICA\n",
    "        if not row[\"ref_matches\"]:\n",
    "            return None\n",
    "        return \" | \".join(row[\"ref_matches\"])\n",
    "\n",
    "    df[\"modelo\"] = df.apply(_modelo_row, axis=1)\n",
    "\n",
    "    # para GENERICO, marca consolidadas a partir de los matches\n",
    "    def _marca_modelo_row(row):\n",
    "        if row[brand_col] == \"GENERICO\" and row[\"marca_matches\"]:\n",
    "            return \" | \".join(row[\"marca_matches\"])\n",
    "        return row[brand_col]\n",
    "\n",
    "    df[\"marca_modelo\"] = df.apply(_marca_modelo_row, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(DATA_PATH)  # o pd.read_csv(...)\n",
    "\n",
    "df_consolidado = consolidar_modelos(\n",
    "    df=df,\n",
    "    title_col=TITLE_COL,                       # ajusta si tu columna tiene otro nombre\n",
    "    brand_col=BRAND_COL,\n",
    "    results_dir=RESULTS_DIR\n",
    ")\n",
    "\n",
    "# Revisión rápida\n",
    "df_consolidado[[ \"marca\", \"marca_modelo\", \"ref_matches\", \"modelo\" ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdf065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5294af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas_motos = [\n",
    "    'AKT', 'BAJAJ', 'HONDA', 'KYMCO', 'SUZUKI', 'KAWASAKI', 'YAMAHA', 'HERO',\n",
    "    'VICTORY', 'KTM', 'TVS', 'BENELLI', 'ROYAL ENFIELD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e369cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado[~(df_consolidado.marca.isin(marcas_motos) & (df_consolidado.modelo.isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd52bf",
   "metadata": {},
   "source": [
    "### Agregar dimensiones para las llantas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee906ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura tu set de marcas de llantas\n",
    "MARCAS_LLANTAS = {\"MICHELIN\", \"PIRELLI\", \"BENELLI\", \"KONTROL\", \"METZELER\"}\n",
    "\n",
    "# Patrones típicos en tags (separados por coma) tipo \"ALTO_90, ANCHO_120, RIN_18, LI_62, SR_S\"\n",
    "# Agrega variantes si las ves en tu data (p. ej., PERFIL_90, DIAMETRO_18, A_120, etc.)\n",
    "PATTERNS = {\n",
    "    \"ancho\":  re.compile(r\"\\b(?:ANCHO|W|ANCHURA)_(\\d{2,3})\\b\", re.I),\n",
    "    \"alto\":   re.compile(r\"\\b(?:ALTO|PERFIL|AR)_(\\d{2,3})\\b\", re.I),\n",
    "    \"rin\":    re.compile(r\"\\b(?:RIN|RIM|DIAMETRO)_(\\d{1,2})\\b\", re.I),\n",
    "    \"li\":     re.compile(r\"\\b(?:LI|LOAD[_\\- ]?INDEX)_(\\d{2,3})\\b\", re.I),\n",
    "    \"sr\":     re.compile(r\"\\b(?:SR|SPEED[_\\- ]?RATING)_([A-Z])\\b\", re.I),\n",
    "}\n",
    "\n",
    "def _norm_tags(tags_val) -> str:\n",
    "    \"\"\"Convierte tags a cadena 'ALTO_90, ANCHO_120, ...' segura para regex.\"\"\"\n",
    "    if tags_val is None:\n",
    "        return \"\"\n",
    "    if isinstance(tags_val, list):\n",
    "        s = \", \".join(str(x) for x in tags_val)\n",
    "    else:\n",
    "        s = str(tags_val)\n",
    "    # Normaliza separadores y espacios\n",
    "    s = re.sub(r\"[;|]+\", \",\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def extract_tire_dims_from_tags(tags_val: str | list) -> dict:\n",
    "    \"\"\"\n",
    "    Extrae dimensiones de llanta desde tags.\n",
    "    Devuelve SOLO claves identificadas. Numéricos como int.\n",
    "    \"\"\"\n",
    "    s = _norm_tags(tags_val).upper()\n",
    "    out = {}\n",
    "    m = PATTERNS[\"ancho\"].search(s)\n",
    "    if m: out[\"ancho\"] = int(m.group(1))\n",
    "    m = PATTERNS[\"alto\"].search(s)\n",
    "    if m: out[\"alto\"] = int(m.group(1))\n",
    "    m = PATTERNS[\"rin\"].search(s)\n",
    "    if m: out[\"rin\"]  = int(m.group(1))\n",
    "    m = PATTERNS[\"li\"].search(s)\n",
    "    if m: out[\"li\"]   = int(m.group(1))\n",
    "    m = PATTERNS[\"sr\"].search(s)\n",
    "    if m: out[\"sr\"]   = m.group(1)\n",
    "    return out\n",
    "\n",
    "def dims_to_str(d: dict) -> str:\n",
    "    if not d: \n",
    "        return \"\"\n",
    "    order = [\"ancho\", \"alto\", \"rin\", \"li\", \"sr\"]\n",
    "    labels = {\"ancho\": \"ANCHO\", \"alto\": \"ALTO\", \"rin\": \"RIN\", \"li\": \"LI\", \"sr\": \"SR\"}\n",
    "    parts = []\n",
    "    for k in order:\n",
    "        if k in d:\n",
    "            parts.append(f\"{labels[k]}: {d[k]}\")\n",
    "    return \"; \".join(parts)\n",
    "\n",
    "def add_tire_dimensions_columns(df: pd.DataFrame, brand_col=\"marca\", tags_col=\"tags\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"dimensiones_dict\"] = None\n",
    "    df[\"dimensiones_str\"] = \"\"\n",
    "\n",
    "    mask_llanta = df[brand_col].astype(str).str.upper().isin(MARCAS_LLANTAS)\n",
    "\n",
    "    # Solo procesar las marcas de llantas\n",
    "    df.loc[mask_llanta, \"dimensiones_dict\"] = df.loc[mask_llanta, tags_col]\\\n",
    "        .apply(lambda x: extract_tire_dims_from_tags(x))\n",
    "\n",
    "    df.loc[mask_llanta, \"dimensiones_str\"] = df.loc[mask_llanta, \"dimensiones_dict\"]\\\n",
    "        .apply(dims_to_str)\n",
    "\n",
    "    # Para no-llantas: quedan vacías (None / \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf93fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado = add_tire_dimensions_columns(\n",
    "    df_consolidado,\n",
    "    brand_col=\"marca\",      \n",
    "    tags_col=\"tags\"         \n",
    ")\n",
    "\n",
    "# ejemplo de inspección para llantas\n",
    "df_consolidado.loc[df_consolidado[\"marca\"].str.upper().isin(MARCAS_LLANTAS),\n",
    "                   [\"marca\", \"tags\", \"dimensiones_dict\", \"dimensiones_str\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f11bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247a459",
   "metadata": {},
   "source": [
    "## Columnas finales recomendadas para indexación\n",
    "\n",
    "### Texto para embeddings\n",
    "- **`texto`** *(string)*: Concatenación del título, descripción y (opcional) modelos y dimensiones cuando apliquen.\n",
    "\n",
    "### Identidad / tracking\n",
    "- **`id_producto`** *(string)*: Identificador único del producto como cadena.\n",
    "- **`url`** *(string)*: URL de la tienda o página del producto.\n",
    "\n",
    "### Marca / modelo\n",
    "- **`marca_original`** *(string)*: Marca original del producto (puede ser `\"GENERICO\"`).\n",
    "- **`marca`** *(string)*: Marca efectiva para búsqueda.\n",
    "  - Para no genéricos: igual a `marca_original`.\n",
    "  - Para genéricos: valor de `marca_modelo` (puede contener varias marcas separadas por `|`).\n",
    "- **`marcas_lista`** *(lista de strings)*: Lista de marcas, dividiendo `marca` por `\" | \"` (útil para filtros `IN`).\n",
    "- **`modelos_lista`** *(lista de strings)*: Todas las referencias o modelos detectados (`ref_matches`).\n",
    "- **`modelo`** *(string)*: `modelos_lista` unida con `\" | \"`.\n",
    "\n",
    "### Producto / categoría\n",
    "- **`categoria`** *(string)*: Categoría principal, normalmente tomada de `tipo_producto`.\n",
    "- **`subcategoria`** *(string, opcional)*: Subtipo de producto si está disponible.\n",
    "- **`es_llanta`** *(booleano)*: Indica si el producto es una llanta.\n",
    "\n",
    "### Tipo de repuesto (original / genérico)\n",
    "- **`tipo_repuesto`** *(string)*: `\"ORIGINAL\"` si `es_original` es verdadero, de lo contrario `\"GENERICO\"`.\n",
    "\n",
    "### Dimensiones (solo relevante para llantas)\n",
    "- **`dimensiones`** *(diccionario)*: Dimensiones de la llanta si aplica, vacío `{}` si no es llanta.\n",
    "  - Claves típicas: `ancho` *(int)*, `alto` *(int)*, `rin` *(int)*, `li` *(int)*, `sr` *(string)*.\n",
    "- **`dimensiones_str`** *(string)*: Representación legible de las dimensiones (útil para UI).\n",
    "\n",
    "### Etiquetas / tags\n",
    "- **`etiquetas`** *(lista de strings)*: Lista de etiquetas normalizadas (mayúsculas y sin espacios extra).\n",
    "\n",
    "---\n",
    "\n",
    "Estas columnas permiten:\n",
    "- Generar **embeddings** a partir de `texto`.\n",
    "- Realizar **filtros estructurados** en Qdrant por:\n",
    "  - `marcas_lista`\n",
    "  - `modelos_lista`\n",
    "  - `categoria`\n",
    "  - `tipo_repuesto`\n",
    "  - `es_llanta`\n",
    "  - Campos numéricos en `dimensiones` (p.ej. `dimensiones.ancho`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf242e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6481cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "MARCAS_LLANTAS = {\"MICHELIN\", \"PIRELLI\", \"BENELLI\", \"KONTROL\", \"METZELER\"}\n",
    "\n",
    "def _a_lista_desde_tags(tags_val) -> List[str]:\n",
    "    if tags_val is None:\n",
    "        return []\n",
    "    if isinstance(tags_val, list):\n",
    "        items = tags_val\n",
    "    else:\n",
    "        items = re.split(r\"[;,|]\", str(tags_val))\n",
    "    return [re.sub(r\"\\s+\", \" \", x).strip().upper() for x in items if str(x).strip()]\n",
    "\n",
    "def _marca_efectiva(row) -> str:\n",
    "    # GENERICO hereda de 'marca_modelo' (puede traer varias marcas con \" | \")\n",
    "    marca_raw = str(row.get(\"marca\", \"\")).strip()\n",
    "    marca_mod = str(row.get(\"marca_modelo\", \"\") or \"\").strip()\n",
    "    if marca_raw.upper() == \"GENERICO\" and marca_mod:\n",
    "        return marca_mod\n",
    "    return marca_raw\n",
    "\n",
    "def _lista_marcas(marca_str: str) -> List[str]:\n",
    "    if not marca_str:\n",
    "        return []\n",
    "    return [p.strip() for p in marca_str.split(\"|\") if p.strip()]\n",
    "\n",
    "def _lista_modelos(row) -> List[str]:\n",
    "    vals = row.get(\"ref_matches\", []) or []\n",
    "    vistos = set(); out = []\n",
    "    for v in vals:\n",
    "        v2 = str(v).strip().upper()\n",
    "        if v2 and v2 not in vistos:\n",
    "            vistos.add(v2); out.append(v2)\n",
    "    return out\n",
    "\n",
    "def _modelo_str(modelos: List[str]) -> str:\n",
    "    return \" | \".join(modelos) if modelos else \"\"\n",
    "\n",
    "def _tipo_repuesto(row) -> str:\n",
    "    return \"ORIGINAL\" if bool(row.get(\"es_original\", False)) else \"GENERICO\"\n",
    "\n",
    "def _es_llanta(row) -> bool:\n",
    "    # Preferir flag explícito\n",
    "    if \"es_llanta\" in row:\n",
    "        return bool(row[\"es_llanta\"])\n",
    "    # fallback conservador\n",
    "    return str(row.get(\"categoria_general\", \"\")).upper() == \"LLANTA\" or \\\n",
    "           str(row.get(\"marca\", \"\")).upper() in MARCAS_LLANTAS\n",
    "\n",
    "def _dicc_dimensiones(row) -> Dict[str, Any]:\n",
    "    # if _es_llanta(row):\n",
    "    #     d = row.get(\"dimensiones_dict\") or {}\n",
    "    #     out = {}\n",
    "    #     for k in [\"ancho\", \"alto\", \"rin\", \"li\"]:\n",
    "    #         if k in d and d[k] not in (None, \"\"):\n",
    "    #             try:\n",
    "    #                 out[k] = int(d[k])\n",
    "    #             except Exception:\n",
    "    #                 pass\n",
    "    #     if \"sr\" in d and d[\"sr\"]:\n",
    "    #         out[\"sr\"] = str(d[\"sr\"]).upper()\n",
    "    #     return out\n",
    "    return row.get(\"dimensiones_dict\") or {}\n",
    "\n",
    "def _dimensiones_str(row) -> str:\n",
    "    return row.get(\"dimensiones_str\", \"\") if _es_llanta(row) else \"\"\n",
    "\n",
    "def _texto_para_embedding(row) -> str:\n",
    "    partes = []\n",
    "    \n",
    "    # 1. Limpieza del título\n",
    "    titulo = str(row.get(\"titulo_producto\", \"\")).strip()\n",
    "    # Elimina \"original\", \"(original)\" y derivados (insensible a mayúsculas/minúsculas)\n",
    "    titulo_limpio = re.sub(r\"\\(?\\b(original|generico|parts|part)\\b\\)?\", \"\", titulo, flags=re.IGNORECASE)\n",
    "    titulo_limpio = re.sub(r\"\\s{2,}\", \" \", titulo_limpio).strip()\n",
    "\n",
    "    if not bool(row.get(\"es_original\", False)):\n",
    "        # Es genérico\n",
    "        titulo_limpio = f\"{titulo_limpio} - Generico\"\n",
    "    else:\n",
    "        titulo_limpio = f\"{titulo_limpio} - Original\"\n",
    "    \n",
    "    # 2. Marca efectiva (puede traer varias marcas separadas por |)\n",
    "    marca = str(row.get(\"__marca_efectiva\", row.get(\"marca\", \"\"))).strip()\n",
    "    \n",
    "    # 3. Modelos ya consolidados\n",
    "    modelo = row.get(\"__modelo_str\", \"\")\n",
    "    \n",
    "    # Construcción final: título limpio, marca, modelos (si existen)\n",
    "    if titulo_limpio:\n",
    "        partes.append(f\"{titulo_limpio}\")\n",
    "    if marca:\n",
    "        partes.append(f\"Marca: {marca}\")\n",
    "    if modelo:\n",
    "        partes.append(f\"Modelos: {modelo}\")\n",
    "    \n",
    "    return \" \\n\".join(partes)\n",
    "\n",
    "def construir_dataset_final_es(df_consolidado: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_consolidado.copy()\n",
    "\n",
    "    # Derivados\n",
    "    df[\"__marca_efectiva\"] = df.apply(_marca_efectiva, axis=1)\n",
    "    df[\"__marcas_lista\"]   = df[\"__marca_efectiva\"].apply(_lista_marcas)\n",
    "    df[\"__modelos_lista\"]  = df.apply(_lista_modelos, axis=1)\n",
    "    df[\"__modelo_str\"]     = df[\"__modelos_lista\"].apply(_modelo_str)\n",
    "    df[\"__tipo_repuesto\"]  = df.apply(_tipo_repuesto, axis=1)\n",
    "    df[\"__etiquetas\"]      = df[\"tags\"].apply(_a_lista_desde_tags)\n",
    "    df[\"__dimensiones\"]    = df.apply(_dicc_dimensiones, axis=1)\n",
    "\n",
    "    # Texto para embeddings\n",
    "    df[\"texto\"] = df.apply(_texto_para_embedding, axis=1)\n",
    "\n",
    "    # Selección y renombre a español (conservando id_producto)\n",
    "    df_final = pd.DataFrame({\n",
    "        \"id_producto\": df[\"id_producto\"].astype(str),\n",
    "        \"titulo\": df[\"titulo_producto\"].astype(str),\n",
    "        \"descripcion\": df[\"descripcion\"].astype(str),\n",
    "        \"texto\": df[\"texto\"],                          # campo a vectorizar\n",
    "        \"url\": df[\"url_tienda\"].astype(str),\n",
    "\n",
    "        \"marca_original\": df[\"marca\"].astype(str),     # puede ser GENERICO\n",
    "        \"marca\": df[\"__marca_efectiva\"].astype(str),   # marca efectiva (puede ser 'A | B' si generico)\n",
    "        \"marcas_lista\": df[\"__marcas_lista\"],          # lista (para filtros IN)\n",
    "\n",
    "        \"modelos_lista\": df[\"__modelos_lista\"],        # todas las refs encontradas\n",
    "        \"modelo\": df[\"__modelo_str\"],                  # join con |\n",
    "\n",
    "        \"categoria\": df[\"categoria_general\"].astype(str),  # categoría principal\n",
    "        \"subcategoria\": df.get(\"subtipo_producto\", \"\"),# opcional\n",
    "\n",
    "        \"tipo_repuesto\": df[\"__tipo_repuesto\"],        # ORIGINAL / GENERICO\n",
    "        \"es_llanta\": df[\"es_llanta\"],\n",
    "\n",
    "        \"dimensiones\": df[\"__dimensiones\"],            # dict (solo llantas)\n",
    "        \"dimensiones_str\": df[\"dimensiones_str\"],    # string humano\n",
    "\n",
    "        \"etiquetas\": df[\"__etiquetas\"],                # tags normalizados\n",
    "        \"precio\": df[\"precio_producto\"],                # tags normalizados\n",
    "    })\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1cfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_consolidado = ... (tu dataframe tras consolidar modelos y dimensiones)\n",
    "df_final = construir_dataset_final_es(df_consolidado)\n",
    "\n",
    "# vistazo\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.iloc[0,:].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.marca_original==\"GENERICO\"].iloc[4000,:].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sample(10).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548beb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel(\"../data/curated/shopify_data_to_index.xlsx\", index=False)\n",
    "#df_final.to_pickle(\"../data/curated/shopify_data_to_index.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.marca_original.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.marca_original.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0adedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.tipo_repuesto.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.categoria.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.categoria=='EMBRAGUE / CLUTCH'].sample(20).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.categoria=='TRANSMISION SECUNDARIA'].sample(10).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.categoria=='LLANTA'].sample(10).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.subcategoria.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.subcategoria.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76089432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =  [\"titulo\"]\n",
    "value_counts_dict = {\" - \".join(cols): df_final[cols].value_counts().to_dict()}\n",
    "value_counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c58f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872454ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437daf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190baa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ddb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# ====== helpers de normalización y regex (mismos que antes) ======\n",
    "\n",
    "def canon_upper(s: str) -> str:\n",
    "    s2 = s.upper()\n",
    "    s2 = re.sub(r\"[\\s\\-_\\.]+\", \" \", s2)\n",
    "    s2 = re.sub(r\"\\s+\", \" \", s2).strip()\n",
    "    return s2\n",
    "\n",
    "_SEP = r\"[\\s\\-_\\.]*\"\n",
    "\n",
    "def _split_letters_digits(token: str) -> List[str]:\n",
    "    pieces = re.findall(r\"[A-Z]+|\\d+\", token)\n",
    "    return pieces if pieces else [token]\n",
    "\n",
    "def _variant_to_pattern(variant: str) -> str:\n",
    "    v = canon_upper(variant)\n",
    "    tokens: List[str] = []\n",
    "    for coarse in v.split():\n",
    "        tokens += _split_letters_digits(coarse)\n",
    "    parts = [re.escape(t) for t in tokens if t]\n",
    "    core = _SEP.join(parts) if parts else re.escape(v)\n",
    "    return rf\"(?<![A-Z0-9]){core}(?![A-Z0-9])\"\n",
    "\n",
    "def build_index_from_consolidated(consolidated: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    entries: List[Dict[str, Any]] = []\n",
    "    for g in consolidated.get(\"grupos\", []):\n",
    "        ref_base = canon_upper(g[\"referencia\"])\n",
    "        variantes = g.get(\"variantes\", []) or [ref_base]\n",
    "        # asegúrate de incluir la referencia base como variante\n",
    "        if ref_base not in (canon_upper(x) for x in variantes):\n",
    "            variantes = [ref_base] + variantes\n",
    "        for v in variantes:\n",
    "            pat = _variant_to_pattern(v)\n",
    "            tokens_count = len(re.findall(r\"[A-Z]+|\\d+\", canon_upper(v)))\n",
    "            weight = (len(canon_upper(v)), tokens_count)\n",
    "            entries.append({\n",
    "                \"referencia_base\": ref_base,\n",
    "                \"variante\": v,\n",
    "                \"regex\": re.compile(pat),\n",
    "                \"weight\": weight,\n",
    "            })\n",
    "    # más largo / más tokens primero\n",
    "    entries.sort(key=lambda e: e[\"weight\"], reverse=True)\n",
    "    return entries\n",
    "\n",
    "def match_first(title: str, index: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    if not isinstance(title, str) or not title:\n",
    "        return {\"ref_match\": None, \"variante_match\": None, \"match_span\": None, \"match_text\": None}\n",
    "    t = canon_upper(title)\n",
    "    for ent in index:\n",
    "        m = ent[\"regex\"].search(t)\n",
    "        if m:\n",
    "            span = m.span()\n",
    "            return {\n",
    "                \"ref_match\": ent[\"referencia_base\"],\n",
    "                \"variante_match\": ent[\"variante\"],\n",
    "                \"match_span\": span,\n",
    "                \"match_text\": t[span[0]:span[1]],\n",
    "            }\n",
    "    return {\"ref_match\": None, \"variante_match\": None, \"match_span\": None, \"match_text\": None}\n",
    "\n",
    "# ====== función para DataFrame ======\n",
    "\n",
    "def apply_reference_matching(\n",
    "    df: pd.DataFrame,\n",
    "    title_col: str,\n",
    "    consolidated: Dict[str, Any],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Añade columnas con el match de referencia a un DataFrame.\n",
    "    - df: DataFrame de entrada\n",
    "    - title_col: nombre de la columna con el título del repuesto\n",
    "    - consolidated: JSON consolidado (marca, grupos, ...)\n",
    "    \"\"\"\n",
    "    if title_col not in df.columns:\n",
    "        raise ValueError(f\"'{title_col}' no existe en el DataFrame\")\n",
    "    index = build_index_from_consolidated(consolidated)\n",
    "\n",
    "    # aplica fila a fila (rápido para ~decenas/centenas de miles; si necesitas más, se puede paralelizar)\n",
    "    matches = df[title_col].apply(lambda s: match_first(s, index))\n",
    "\n",
    "    # expandir dict a columnas\n",
    "    matches_df = pd.DataFrame(list(matches.values)) if hasattr(matches, \"values\") else pd.DataFrame(matches.tolist())\n",
    "    out = df.reset_index(drop=True).join(matches_df)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d79025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "def load_json(path: str | Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Carga un archivo JSON desde la ruta dada y devuelve un dict de Python.\n",
    "    \n",
    "    Parámetros:\n",
    "        path (str | Path): Ruta al archivo JSON.\n",
    "\n",
    "    Devuelve:\n",
    "        dict: Contenido del JSON como diccionario.\n",
    "    \"\"\"\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo: {p.resolve()}\")\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f32824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(\"../data/results/curated/consolidacion_referencias/*.json\")\n",
    "\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"../data/results/curated/consolidacion_referencias\"\n",
    "DATA_PATH = \"../data/curated/shopify_data_cat_gen.pkl\"\n",
    "TITLE_COL = \"titulo_producto\"\n",
    "\n",
    "df = pd.read_pickle(DATA_PATH)  # o pd.read_csv(...)\n",
    "# Asegúrate que la columna de marca exista:\n",
    "assert \"marca\" in df.columns, \"La columna 'marca' no existe en el dataset base\"\n",
    "\n",
    "# --- Iterar JSONs por marca, filtrar y consolidar ---\n",
    "files = sorted(glob(f\"{RESULTS_DIR}/*.json\"))\n",
    "dfs_out: List[pd.DataFrame] = []\n",
    "row_count_expected = 0\n",
    "\n",
    "for fp in files:\n",
    "    consolidated_data = load_json(fp)\n",
    "    marca_json = str(consolidated_data.get(\"marca\", \"\")).upper()\n",
    "    if not marca_json:\n",
    "        # fallback: inferir desde el nombre del archivo (AKT_YYYYMMDD_*.json o AKT.json)\n",
    "        stem = Path(fp).stem\n",
    "        marca_json = stem.split(\"_\")[0].upper()\n",
    "\n",
    "    # filtrar dataset por marca\n",
    "    df_marca = df[df[\"marca\"].str.upper() == marca_json].copy()\n",
    "    if df_marca.empty:\n",
    "        print(f\"[AVISO] No hay filas para marca '{marca_json}' en el dataset base. Archivo: {fp}\")\n",
    "        continue\n",
    "\n",
    "    row_count_expected += len(df_marca)\n",
    "\n",
    "    # aplicar matching referencias a esta marca\n",
    "    df_matched = apply_reference_matching(df_marca, TITLE_COL, consolidated_data)\n",
    "    # (opcional) guarda la marca normalizada, por si no lo está\n",
    "    df_matched[\"marca_norm\"] = marca_json\n",
    "\n",
    "    dfs_out.append(df_matched)\n",
    "    print(f\"✔ {marca_json}: {len(df_marca)} filas procesadas\")\n",
    "\n",
    "# --- DataFrame consolidado ---\n",
    "if dfs_out:\n",
    "    df_consolidado = pd.concat(dfs_out, ignore_index=True)\n",
    "else:\n",
    "    df_consolidado = pd.DataFrame()\n",
    "\n",
    "print(\"\\nResumen\")\n",
    "print(\"  Archivos procesados:\", len(files))\n",
    "print(\"  Filas esperadas (suma por marca):\", row_count_expected)\n",
    "print(\"  Filas en df_consolidado:\", len(df_consolidado))\n",
    "\n",
    "# Verificación dura: deben ser iguales\n",
    "assert len(df_consolidado) == row_count_expected, \\\n",
    "    \"El consolidado no tiene el mismo número de filas que la suma de las marcas analizadas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado[df_consolidado['ref_match'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ca1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.marca.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a54bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.marca.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas_llantas = [\"MICHELIN\", \"PIRELLI\", \"BENELLI\", \"KONTROL\", \"METZELER\"] # para llantas el modelo  (ref_match) no aplica  \n",
    "\n",
    "# para \"GENERICO\" toca aplicar la logica de ref pero con todos los json consolidados (se tendria una columna de ref_match por cada marca) luego se consolida con todas las referencias diferentes que hayan macheado.. Tambien se debe hererdad la marca del producto con el que macheo para completar estta columna para la marca GENERICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd9487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d83e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0690a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038bbe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489657bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el archivo está en data/results/consolidacion_referencias/AKT_20250826_101500.json\n",
    "json_path = \"../data/results/curated/consolidacion_referencias/AKT.json\"\n",
    "consolidated_data = load_json(json_path)\n",
    "\n",
    "print(consolidated_data[\"marca\"])       # ejemplo: AKT\n",
    "print(len(consolidated_data[\"grupos\"])) \n",
    "\n",
    "\n",
    "marca = \"AKT\"\n",
    "df = pd.read_pickle(\"../data/curated/shopify_data_cat_gen.pkl\")\n",
    "df_marca = df[df.marca==marca].reset_index(drop=True)\n",
    "df_marca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd30a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = apply_reference_matching(df_marca, title_col=\"titulo_producto\", consolidated=consolidated_data)\n",
    "\n",
    "# opcional: filtrar solo filas con match\n",
    "df_matched = df_out[df_out[\"ref_match\"].notna()]\n",
    "\n",
    "# guardar resultados\n",
    "df_out.to_csv(\"matched_referencias.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.shape, df_matched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b9cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[df_out['ref_match'].notna()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1482fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[df_out['ref_match'].isna()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a50062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[df_out['ref_match'].notna()].categoria_general.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc48cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['tipo_producto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbbd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
